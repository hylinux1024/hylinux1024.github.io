<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  

  <title>
    
      机器学习之朴素贝叶斯 &middot; hylinux
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="hylinux" />
</head>


  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/">
          <h2 class="nav-title">hylinux</h2>
        </a>
        <ul>
          <li><a href="/about">About</a></li>
          <li><a href="/">Posts</a></li>
        </ul>
      </div>
    </nav>

    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        hylinux1024
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2017-08-08 00:00:00 +0800">August 08, 2017</time>
    
  </div>

  <h1 class="post-title">机器学习之朴素贝叶斯</h1>
  <div class="post-line"></div>

  <p>本文会讲到以下内容</p>

<ol>
  <li>贝叶斯定理</li>
  <li>垃圾邮件分类器</li>
</ol>

<h3 id="贝叶斯定理">贝叶斯定理</h3>

<p>贝叶斯定理又称贝叶斯法则，它的形式为</p>

<script type="math/tex; mode=display">P(A|B)=\frac {P(B|A)P(A)} {P(B)} \tag 1</script>

<p>其中 P(A)、 P(B) 分别为事件 A、B出现的的概率，且 \( P(B) \neq 0 \)</p>

<table>
  <tbody>
    <tr>
      <td>P(A</td>
      <td>B) 为条件概率，表示在 B 事件出现的情况下 A 的概率。</td>
    </tr>
  </tbody>
</table>

<p>P(B) 表示全概率，它可以表示为</p>

<script type="math/tex; mode=display">P(B)=\sum_i^mP(B|A_i)P(A_i) \tag 2</script>

<p>上面式子的意思是 B 事件出现的概率是由因素 m 个\( A_i \) 影响的。</p>

<p>故（1）中的条件概率又可以</p>

<script type="math/tex; mode=display">P(A|B)=\frac {P(B|A)P(A)} {\sum_i^mP(B|A_i)P(A_i)} \tag 3</script>

<p>可以简单地</p>

<script type="math/tex; mode=display">P(A|B)=\frac {P(B|A)P(A)} {P(B|A)P(A)+P(B|\rightharpoondown A)P(\rightharpoondown A)} \tag 4</script>

<p>其中 \( P(A)=1-P(-A) \)</p>

<h3 id="垃圾邮件分类器">垃圾邮件分类器</h3>

<p>在机器学习中贝叶斯分类器经常见的应用是<strong>垃圾邮件分类</strong>。下面我们就运用贝叶斯定理推导一下垃圾邮件的分类模型算法。</p>

<p>假设</p>

<p>\( W_1,W_2,W_3,…,W_i \) 垃圾邮件中出现单词 i 的事件；</p>

<p>S 为垃圾邮件的事件，H 为正常邮件；</p>

<p>P(S) 垃圾邮件概率,P(H) 为正常邮件的概率；</p>

<p>而 P(S)、P(H) 是先验概率，表示在统计之前一封邮件的概率,这里我们假设 P(S) = P(H)=0.5；</p>

<p>\( P(W_i) \) 为单词 i 出现的概率。</p>

<p>那么如果有一份邮件出现了单词 \( W_1 \)，那么它是垃圾邮件和正常邮件的概率分别是多大呢？</p>

<p>根据贝叶斯定理</p>

<script type="math/tex; mode=display">P(S|W_1)=\frac {P(W_1|S)P(S)} {P(W_1)} \\
P(S|W_2)=\frac {P(W_2|S)P(S)} {P(W_2)} \\
\vdots \\
\\
P(S|W_i)=\frac {P(W_i|S)P(S)} {P(W_i)} \\ \tag 5</script>

<p>这样可以计算出每个单词的垃圾邮件的条件概率。</p>

<table>
  <tbody>
    <tr>
      <td>其中 \( P(W_i</td>
      <td>S) \) 表示垃圾邮件中 \( W_i \) 出现的概率，可以根据训练数据可以统计出来。\( P(W_i) \) 也可以从训练数据中得到。</td>
    </tr>
  </tbody>
</table>

<p>但是仅仅根据其中一个单词来判断一封邮件是否是垃圾邮件，显然是不行的。这就需要计算<strong>联合概率（Combining Probabilities）</strong>。</p>

<h4 id="联合概率combining-probabilities">联合概率（Combining Probabilities）</h4>

<p>我们从（5）的式子中选取 n 个概率最大的单词来计算它们的联合概率。</p>

<p>为了简单我们这里取 n=2，于是计算两个单词的联合概率</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1,W_2|S)P(S)} {P(W_1,W_2)} \tag 6</script>

<p>又由于我们假设单词 \( W_1,W_2 \) 是相互独立的（实际上不是，但是这个假设很有用，而且这样假设实际效果很不错，所以才称之为<strong>朴素贝叶斯</strong>）</p>

<p>所以</p>

<script type="math/tex; mode=display">P(W_1,W_2|S)=P(W_1|S)P(W_2|S) \tag 7</script>

<p>又根据全概率公式有</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}\begin{split}P(W_1,W_2)&=P(W_1,W_2|S)P(S) +P(W_1,W_2|S)P(H)\\
&=P(W_1|S)P(W_2|S) P(S)+P(W_1|H)P(W_2|H)P(H) \end{split}\end{equation}\tag 8 %]]></script>

<p>由（6）（7）（8）</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S) P(S)} {P(W_1|S)P(W_2|S) P(S)+P(W_1|H)P(W_2|H)P(H)} \tag 9</script>

<p>将 P(S)=P(H)=0.5 代入</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S)} {P(W_1|S)P(W_2|S) +P(W_1|H)P(W_2|H)} \tag {10}</script>

<p>且有</p>

<script type="math/tex; mode=display">P(W_1|H)=P(W_1|-S)=1-P(W_1|S)\\
P(W_2|H)=P(W_2|-S)=1-P(W_2|S) \tag {11}</script>

<p>最终</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S)} {P(W_1|S)P(W_2|S) +(1-P(W_1|S))(1-P(W_2|S))} \tag {12}</script>

<p>这个就是 \( W_1,W_2 \) 的<strong>联合概率</strong>。</p>

<p>一般地</p>

<script type="math/tex; mode=display">P(S|W_1,W_2,...,W_i)=\frac {P_1P_2...P_i} {P_1P_2...P_3 +(1-P_1)(1-P_2)...(1-P_i)} \tag {13}</script>

<p>上式就是<strong>垃圾邮件的分类模型</strong>。</p>

<h4 id="参考文档">参考文档</h4>

<p>http://cs229.stanford.edu/materials.html</p>

<p>http://www.mathpages.com/home/kmath267/kmath267.htm</p>

<p>https://en.wikipedia.org/wiki/Bayes%27_theorem</p>

<p>http://www.paulgraham.com/spam.html</p>



</div>

<div class="pagination">
  
    <a href="/2017-08-20/logisitic-regression" class="left arrow">&#8592;</a>
  
  
    <a href="/2017-08-07/linear-regression" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
      <span>
        &copy; <time datetime="2018-09-27 21:39:01 +0800">2018</time> hylinux1024. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
      </span>
    </footer>
  </body>
</html>
