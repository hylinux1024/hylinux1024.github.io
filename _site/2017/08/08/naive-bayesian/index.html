<!DOCTYPE html>
<html>
    <head>
        <meta http-equiv="content-type" content="text/html;charset=utf-8"/>
        <meta name="keywords" content="朴素贝叶斯,Naive Bayesian" />
        <meta name="description" content="贝叶斯定理又称贝叶斯法则。" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <title> 机器学习之朴素贝叶斯  </title>
        <link rel="stylesheet" href="http://localhost:4000/css/default.css" type="text/css" />
        <link rel="stylesheet" href="http://localhost:4000/css/small.css" type="text/css" media="(max-width: 720px)"/>
        <link rel="stylesheet" href="http://localhost:4000/css/syntax.css" type="text/css" />
        <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" type="image/x-icon" />
        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    </head>
    <body>

<div class="container">
    <div class="nav">
    <div class="nav_nav">
        <a class="nav_a1" href="http://localhost:4000/">首页</a>
        <a href="http://localhost:4000/categories/">分类</a>
        <a class="nav_a1" href="http://localhost:4000/wiki/">维基</a>
        <a href="http://localhost:4000/links/">链接</a>
        <a class="nav_a1" href="http://localhost:4000/about/">关于</a>
    </div>
    <div class="nav_rss"><a href="http://localhost:4000/sitemap.xml" style="display:none;">SITEMAP</a><a href="http://localhost:4000/feed.xml" target="_blank">订阅</a></div>
</div>

    <div class="main">
        <h2> 机器学习之朴素贝叶斯 </h2>
        <p>本文会讲到以下内容</p>

<ol>
  <li>贝叶斯定理</li>
  <li>垃圾邮件分类器</li>
</ol>

<h3 id="贝叶斯定理">贝叶斯定理</h3>

<p>贝叶斯定理又称贝叶斯法则，它的形式为</p>

<script type="math/tex; mode=display">P(A|B)=\frac {P(B|A)P(A)} {P(B)} \tag 1</script>

<p>其中 P(A)、 P(B) 分别为事件 A、B出现的的概率，且 \( P(B) \neq 0 \)</p>

<table>
  <tbody>
    <tr>
      <td>P(A</td>
      <td>B) 为条件概率，表示在 B 事件出现的情况下 A 的概率。</td>
    </tr>
  </tbody>
</table>

<p>P(B) 表示全概率，它可以表示为</p>

<script type="math/tex; mode=display">P(B)=\sum_i^mP(B|A_i)P(A_i) \tag 2</script>

<p>上面式子的意思是 B 事件出现的概率是由因素 m 个\( A_i \) 影响的。</p>

<p>故（1）中的条件概率又可以</p>

<script type="math/tex; mode=display">P(A|B)=\frac {P(B|A)P(A)} {\sum_i^mP(B|A_i)P(A_i)} \tag 3</script>

<p>可以简单地</p>

<script type="math/tex; mode=display">P(A|B)=\frac {P(B|A)P(A)} {P(B|A)P(A)+P(B|\rightharpoondown A)P(\rightharpoondown A)} \tag 4</script>

<p>其中 \( P(A)=1-P(-A) \)</p>

<h3 id="垃圾邮件分类器">垃圾邮件分类器</h3>

<p>在机器学习中贝叶斯分类器经常见的应用是<strong>垃圾邮件分类</strong>。下面我们就运用贝叶斯定理推导一下垃圾邮件的分类模型算法。</p>

<p>假设</p>

<p>\( W_1,W_2,W_3,…,W_i \) 垃圾邮件中出现单词 i 的事件；</p>

<p>S 为垃圾邮件的事件，H 为正常邮件；</p>

<p>P(S) 垃圾邮件概率,P(H) 为正常邮件的概率；</p>

<p>而 P(S)、P(H) 是先验概率，表示在统计之前一封邮件的概率,这里我们假设 P(S) = P(H)=0.5；</p>

<p>\( P(W_i) \) 为单词 i 出现的概率。</p>

<p>那么如果有一份邮件出现了单词 \( W_1 \)，那么它是垃圾邮件和正常邮件的概率分别是多大呢？</p>

<p>根据贝叶斯定理</p>

<script type="math/tex; mode=display">P(S|W_1)=\frac {P(W_1|S)P(S)} {P(W_1)} \\
P(S|W_2)=\frac {P(W_2|S)P(S)} {P(W_2)} \\
\vdots \\
\\
P(S|W_i)=\frac {P(W_i|S)P(S)} {P(W_i)} \\ \tag 5</script>

<p>这样可以计算出每个单词的垃圾邮件的条件概率。</p>

<table>
  <tbody>
    <tr>
      <td>其中 \( P(W_i</td>
      <td>S) \) 表示垃圾邮件中 \( W_i \) 出现的概率，可以根据训练数据可以统计出来。\( P(W_i) \) 也可以从训练数据中得到。</td>
    </tr>
  </tbody>
</table>

<p>但是仅仅根据其中一个单词来判断一封邮件是否是垃圾邮件，显然是不行的。这就需要计算<strong>联合概率（Combining Probabilities）</strong>。</p>

<h4 id="联合概率combining-probabilities">联合概率（Combining Probabilities）</h4>

<p>我们从（5）的式子中选取 n 个概率最大的单词来计算它们的联合概率。</p>

<p>为了简单我们这里取 n=2，于是计算两个单词的联合概率</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1,W_2|S)P(S)} {P(W_1,W_2)} \tag 6</script>

<p>又由于我们假设单词 \( W_1,W_2 \) 是相互独立的（实际上不是，但是这个假设很有用，而且这样假设实际效果很不错，所以才称之为<strong>朴素贝叶斯</strong>）</p>

<p>所以</p>

<script type="math/tex; mode=display">P(W_1,W_2|S)=P(W_1|S)P(W_2|S) \tag 7</script>

<p>又根据全概率公式有</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}\begin{split}P(W_1,W_2)&=P(W_1,W_2|S)P(S) +P(W_1,W_2|S)P(H)\\
&=P(W_1|S)P(W_2|S) P(S)+P(W_1|H)P(W_2|H)P(H) \end{split}\end{equation}\tag 8 %]]></script>

<p>由（6）（7）（8）</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S) P(S)} {P(W_1|S)P(W_2|S) P(S)+P(W_1|H)P(W_2|H)P(H)} \tag 9</script>

<p>将 P(S)=P(H)=0.5 代入</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S)} {P(W_1|S)P(W_2|S) +P(W_1|H)P(W_2|H)} \tag {10}</script>

<p>且有</p>

<script type="math/tex; mode=display">P(W_1|H)=P(W_1|-S)=1-P(W_1|S)\\
P(W_2|H)=P(W_2|-S)=1-P(W_2|S) \tag {11}</script>

<p>最终</p>

<script type="math/tex; mode=display">P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S)} {P(W_1|S)P(W_2|S) +(1-P(W_1|S))(1-P(W_2|S))} \tag {12}</script>

<p>这个就是 \( W_1,W_2 \) 的<strong>联合概率</strong>。</p>

<p>一般地</p>

<script type="math/tex; mode=display">P(S|W_1,W_2,...,W_i)=\frac {P_1P_2...P_i} {P_1P_2...P_3 +(1-P_1)(1-P_2)...(1-P_i)} \tag {13}</script>

<p>上式就是<strong>垃圾邮件的分类模型</strong>。</p>

<h4 id="参考文档">参考文档</h4>

<p>http://cs229.stanford.edu/materials.html</p>

<p>http://www.mathpages.com/home/kmath267/kmath267.htm</p>

<p>https://en.wikipedia.org/wiki/Bayes%27_theorem</p>

<p>http://www.paulgraham.com/spam.html</p>


        
        <div class="post_footer">
          <p>Published on Aug 08, 2017 in categories 
          
          <a href="http://localhost:4000/categories/#ML" title="ML">ML</a>&nbsp;
          
          <p>
        </div>
        
        <ul class="prev_next">
            
            <li>
                <span>上一篇</span>
                <a href="/2017/08/07/linear-regression/">机器学习之线性回归</a>
            </li>
            
            
            <li>
                <span>下一篇</span>
                <a href="/2017/08/20/logisitic-regression/">机器学习之逻辑回归</a>
            </li>
            
        </ul>
        <hr>
<div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a><a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a></div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

        

  

  
        <div id="container"></div>
        <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
        <script src="http://localhost:4000/js/gitment.browser.js"></script>
        <script>
        var gitment = new Gitment({
            id: '/2017/08/08/naive-bayesian/',
            owner: 'hylinux1024',
            repo: 'hylinux1024.github.io',
            oauth: {
                client_id: 'c79c9ae57765adcce459',
                client_secret: '09264b1c3c58033878872c924196898c9931a8e5',
            },
        })
        gitment.render('container')
        </script>
  


    </div>
</div>
<center><p style="font-size:0.5em;">Powered by <a href="http://jekyllrb.com">Jekyll</a> and Theme by <a href="http://github.com/mzlogin/jekyll-theme-solid">solid</a></p></center>
    </body>
</html>

