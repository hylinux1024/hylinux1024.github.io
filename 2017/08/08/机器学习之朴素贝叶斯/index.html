<html>
<head>
	
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><title>机器学习之朴素贝叶斯</title>
	<meta name="keywords" content="Machine Learning,Deep Learning" />

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    
    <!--<link rel="stylesheet" href="/css/main.css">-->
	<link href="/css/main.css?v=2" rel="stylesheet" type="text/css" />
    <!--<link rel="stylesheet" href="/css/style.css">-->
    

    <link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Atom feed">

    
	<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2"/><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><h2 class="title">机器学习之朴素贝叶斯</h2>
<p>本文会讲到以下内容</p>
<ol>
<li>贝叶斯定理</li>
<li>垃圾邮件分类器</li>
</ol>
<h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><p>贝叶斯定理又称贝叶斯法则，它的形式为</p>
<script type="math/tex; mode=display">
P(A|B)=\frac {P(B|A)P(A)} {P(B)} \tag 1</script><p>其中 P(A)、 P(B) 分别为事件 A、B出现的的概率，且 \( P(B) \neq 0 \)</p>
<p>P(A|B) 为条件概率，表示在 B 事件出现的情况下 A 的概率。</p>
<p>P(B) 表示全概率，它可以表示为</p>
<script type="math/tex; mode=display">
P(B)=\sum_i^mP(B|A_i)P(A_i) \tag 2</script><p>上面式子的意思是 B 事件出现的概率是由因素 m 个\( A_i \) 影响的。</p>
<p>故（1）中的条件概率又可以</p>
<script type="math/tex; mode=display">
P(A|B)=\frac {P(B|A)P(A)} {\sum_i^mP(B|A_i)P(A_i)} \tag 3</script><p>可以简单地</p>
<script type="math/tex; mode=display">
P(A|B)=\frac {P(B|A)P(A)} {P(B|A)P(A)+P(B|\rightharpoondown A)P(\rightharpoondown A)} \tag 4</script><p>其中 \( P(A)=1-P(-A) \)</p>
<h3 id="垃圾邮件分类器"><a href="#垃圾邮件分类器" class="headerlink" title="垃圾邮件分类器"></a>垃圾邮件分类器</h3><p>在机器学习中贝叶斯分类器经常见的应用是<strong>垃圾邮件分类</strong>。下面我们就运用贝叶斯定理推导一下垃圾邮件的分类模型算法。</p>
<p>假设</p>
<p>\( W_1,W_2,W_3,…,W_i \) 垃圾邮件中出现单词 i 的事件；</p>
<p>S 为垃圾邮件的事件，H 为正常邮件；</p>
<p>P(S) 垃圾邮件概率,P(H) 为正常邮件的概率；</p>
<p>而 P(S)、P(H) 是先验概率，表示在统计之前一封邮件的概率,这里我们假设 P(S) = P(H)=0.5；</p>
<p>\( P(W_i) \) 为单词 i 出现的概率。</p>
<p>那么如果有一份邮件出现了单词 \( W_1 \)，那么它是垃圾邮件和正常邮件的概率分别是多大呢？</p>
<p>根据贝叶斯定理</p>
<script type="math/tex; mode=display">
P(S|W_1)=\frac {P(W_1|S)P(S)} {P(W_1)} \\
P(S|W_2)=\frac {P(W_2|S)P(S)} {P(W_2)} \\
\vdots \\
\\
P(S|W_i)=\frac {P(W_i|S)P(S)} {P(W_i)} \\ \tag 5</script><p>这样可以计算出每个单词的垃圾邮件的条件概率。</p>
<p>其中 \( P(W_i|S) \) 表示垃圾邮件中 \( W_i \) 出现的概率，可以根据训练数据可以统计出来。\( P(W_i) \) 也可以从训练数据中得到。</p>
<p>但是仅仅根据其中一个单词来判断一封邮件是否是垃圾邮件，显然是不行的。这就需要计算<strong>联合概率（Combining Probabilities）</strong>。</p>
<h4 id="联合概率（Combining-Probabilities）"><a href="#联合概率（Combining-Probabilities）" class="headerlink" title="联合概率（Combining Probabilities）"></a>联合概率（Combining Probabilities）</h4><p>我们从（5）的式子中选取 n 个概率最大的单词来计算它们的联合概率。</p>
<p>为了简单我们这里取 n=2，于是计算两个单词的联合概率</p>
<script type="math/tex; mode=display">
P(S|W_1,W_2)=\frac {P(W_1,W_2|S)P(S)} {P(W_1,W_2)} \tag 6</script><p>又由于我们假设单词 \( W_1,W_2 \) 是相互独立的（实际上不是，但是这个假设很有用，而且这样假设实际效果很不错，所以才称之为<strong>朴素贝叶斯</strong>）</p>
<p>所以</p>
<script type="math/tex; mode=display">
P(W_1,W_2|S)=P(W_1|S)P(W_2|S) \tag 7</script><p>又根据全概率公式有</p>
<script type="math/tex; mode=display">
\begin{equation}\begin{split}P(W_1,W_2)&=P(W_1,W_2|S)P(S) +P(W_1,W_2|S)P(H)\\
&=P(W_1|S)P(W_2|S) P(S)+P(W_1|H)P(W_2|H)P(H) \end{split}\end{equation}\tag 8</script><p>由（6）（7）（8）</p>
<script type="math/tex; mode=display">
P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S) P(S)} {P(W_1|S)P(W_2|S) P(S)+P(W_1|H)P(W_2|H)P(H)} \tag 9</script><p>将 P(S)=P(H)=0.5 代入</p>
<script type="math/tex; mode=display">
P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S)} {P(W_1|S)P(W_2|S) +P(W_1|H)P(W_2|H)} \tag {10}</script><p>且有</p>
<script type="math/tex; mode=display">
P(W_1|H)=P(W_1|-S)=1-P(W_1|S)\\
P(W_2|H)=P(W_2|-S)=1-P(W_2|S) \tag {11}</script><p>最终</p>
<script type="math/tex; mode=display">
P(S|W_1,W_2)=\frac {P(W_1|S)P(W_2|S)} {P(W_1|S)P(W_2|S) +(1-P(W_1|S))(1-P(W_2|S))} \tag {12}</script><p>这个就是 \( W_1,W_2 \) 的<strong>联合概率</strong>。</p>
<p>一般地</p>
<script type="math/tex; mode=display">
P(S|W_1,W_2,...,W_i)=\frac {P_1P_2...P_i} {P_1P_2...P_3 +(1-P_1)(1-P_2)...(1-P_i)} \tag {13}</script><p>上式就是<strong>垃圾邮件的分类模型</strong>。</p>
<h4 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h4><p><a href="http://www.mathpages.com/home/kmath267/kmath267.htm" target="_blank" rel="external">http://www.mathpages.com/home/kmath267/kmath267.htm</a></p>
<p><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank" rel="external">https://en.wikipedia.org/wiki/Bayes%27_theorem</a></p>
<p><a href="http://www.paulgraham.com/spam.html" target="_blank" rel="external">http://www.paulgraham.com/spam.html</a></p>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<!--<a href="https://wecodexyz.github.io/2017/08/08/机器学习之朴素贝叶斯/#disqus_thread" class="article-comment-link">Comments</a>-->
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = ''; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<div style="display:none">
<script src="http://s4.cnzz.com/stat.php?id=&web_id=" language="JavaScript"></script>
</div><!-- hexo-inject:begin --><!-- hexo-inject:end -->







</body>
</html>